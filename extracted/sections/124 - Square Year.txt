Square Year
It was midnight on 31 December 2001, and Alfie and Betty – both
of whom were aged less than sixty – were talking about the
calendar.
    ‘At some time in the past, the year was the square of my
father’s age,’ said Betty proudly. ‘He died at the age of a
hundred!’
    ‘And at some time in the future, the year will be the square of
my age,’ Alfie replied. ‘I don’t know whether I’ll reach a hundred,
though.’
    In which years were Betty’s father and Alfie born?


...........................................
      Answer on page 298
                                         Gödel’s Theorems // 205



Gödel’s Theorems
In 1931 the mathematical logician Kurt Gödel proved two
important theorems, of great originality, which placed un-
avoidable limits on the power of formal reasoning in mathe-
matics. Gödel was responding to a research programme initiated
by David Hilbert, who was convinced that the whole of
mathematics could be placed on an axiomatic basis. Which is to
say it should be possible to state a list of basic assumptions, or
‘axioms’, and deduce the rest of mathematics from the axioms.
Additionally, Hilbert expected to be able to prove two key
properties:

. The system is logically consistent – it is not possible to deduce
   two statements that contradict each other.
. The system is complete – every statement has either a proof or
   a disproof.

The kind of axiomatic ‘system’ that Hilbert had in mind was
more basic than, say, arithmetic – something like the theory of
sets introduced by Georg Cantor in 1879 and developed over the
next few years. Starting from sets, there are ways to define whole
numbers, the usual operations of arithmetic, negative and
rational numbers, real numbers, complex numbers, and so on. So
placing set theory on an axiomatic basis would automatically do
the same for the rest of mathematics. And proving that the
axiomatic system for set theory is consistent and complete would
also do the same for the rest of mathematics. Since set theory is
conceptually simpler than arithmetic, this seemed a sensible way
to proceed. In fact, there was even a candidate axiomatisation of
set theory, developed by Betrand Russell and Alfred North
Whitehead in their three-volume epic Principia Mathematica.
There were various alternatives, too.
    Hilbert pushed a substantial part of his programme through
successfully, but there were still some gaps when Gödel arrived
on the scene. Gödel’s 1931 paper ‘On Formally Undecidable
Propositions in Principia Mathematica and Related Systems I’ left
206 // Gödel’s Theorems



Hilbert’s programme in ruins, by proving that no such approach
could ever succeed.
    Gödel went to great lengths to place his proofs in a rigorous
logical context, and to avoid several subtle logical traps. In fact
most of his paper is devoted to setting up these background
ideas, which are very technical – ‘recursively enumerable sets’.
The climax to the paper can be stated informally, as two
dramatic theorems:

. In a formal system that is rich enough to include arithmetic,
    there exist undecidable statements – statements that can
    neither be proved nor disproved within that system.
.   If a formal system that is rich enough to include arithmetic is
    logically consistent, then it is impossible to prove its
    consistency within that system.

The first theorem does not just indicate that finding a proof or
disproof of the appropriate statement is difficult. It established
that no proof exists, and no disproof exists. It means that the
logical distinction between ‘true’ and ‘false’ is not identical to
that between ‘provable’ and ‘disprovable’. In conventional logic
– including that used in Principia Mathematica – every statement
is either true or false, and cannot be both. Since the negation
not-P of any true statement P is false, and the negation of a false
statement is true, conventional logic obeys the ‘law of the
excluded middle’: given any statement P, then exactly one of P
and not-P is true, and the other is false. Either 2þ2 is equal to 4,
or 2þ2 is not equal to 4. It has to be one or the other, and it can’t
be both.
    Now, if P has a proof, then P must be true – this is how
mathematicians establish the truth (in a mathematical sense) of
their theorems. If P has a disproof, then not-P must be true, so P
must be false. But Gödel proved that for some statements P,
neither P nor not-P has a proof. So a statement can be provable,
disprovable – or neither. If it’s neither, it is said to be
‘undecidable’. So now there is a third possibility, and the
‘middle’ is no longer excluded.
                                          Gödel’s Theorems // 207



    Before Gödel, mathematicians had happily assumed that
anything true was provable, and anything false was disprovable.
Finding the proof or disproof might be very hard, but there was
no reason to doubt that one or the other must exist. So
mathematicians considered ‘provable’ to be the same as ‘true’,
and ‘disprovable’ to be the same as ‘false’. And they felt happier
with practical concepts of proof and disproof than with deep and
tricky philosophical concepts like truth and falsity, so mostly
they settled for proofs and disproofs. And so it was disturbing to
discover that these left a gap, a kind of logical no-man’s-land.
And in ordinary arithmetic, too!
    Gödel set up his undecidable statement by finding a formal
version of the logical paradox ‘this statement is false’, or more
accurately of ‘this statement has no proof’. However, in
mathematical logic a statement is not permitted to refer to itself
– in fact, ‘this statement’ is not something that has a meaning
within the formal system concerned. Gödel found a cunning way
to achieve much the same result without breaking the rules, by
associating a numerical code with each formal statement. Then a
proof of any statement corresponded to some sequence of
transformations of the corresponding code number. So the
formal system could model arithmetic – but arithmetic could
also model the formal system.
    Within this set-up, and assuming the formal system to be
logically consistent, the statement P whose interpretation was
basically ‘this statement has no proof’ must be undecidable. If P
has a proof, then P is true, so by its defining property P has no
proof – a contradiction. But the system is assumed to be
consistent, so that can’t happen. On the other hand, if P has no
proof, then P is true. Therefore not-P has no proof. So neither P
nor not-P has a proof.
    From here it is a short step to the second theorem – if the
formal system is consistent, then there can’t be a proof that it is.
I’ve always thought this to be rather plausible. Think of
arithmetic as a used car salesman. Hilbert wanted to ask the
salesman ‘are you honest?’ and get an answer that guaranteed
208 // If p isn’t a Fraction, How Can You Calculate It?



that he was. Gödel basically argued that if you ask him this
question and he says ‘Yes, I am,’ that is no guarantee of honesty.
Would you believe that someone is telling the truth because they
tell you they are? A court of law certainly would not.
     Because of the technical complications, Gödel proved his
theorems within one specific formal system for arithmetic, the
one in Principia Mathematica. So a possible consequence might
have been that this system is inadequate, and something better is
needed. But Gödel pointed out in the introduction to his paper
that a similar line of reasoning would apply to any alternative
formal system for arithmetic. Changing the axioms wouldn’t
help. His successors filled in the necessary details, and Hilbert’s
programme was a dead duck.
     Several important mathematical problems are now known to
be undecidable. The most famous is probably the halting
problem for Turing machines – which in effect asks for a method
to determine in advance whether a computer program will
eventually stop with an answer, or go on for ever. Alan Turing
proved that some programs are undecidable – there is no way to


...........................................
prove that they stop, and no way to prove that they don’t.



If p isn’t a Fraction, How Can You Calculate It?
The school value 22/7 for p is not exact. It’s not even terribly
good. But it is good for something so simple. Since we know that
p is not an exact fraction, it’s not obvious how it can be
calculated to very high accuracy. Mathematicians achieve this
using a variety of cunning formulas for p, all of which are exact,
and all of which involve some process that goes on for ever. By
stopping before we get to ‘for ever’, a good approximation to p
can be found.
    In fact, mathematics presents us with an embarrassment of
riches, because one of the perennial fascinations of p is its
tendency to appear in a huge variety of beautiful formulas.
Typically they are infinite series, infinite products or infinite
               If p isn’t a Fraction, How Can You Calculate It? // 209



fractions (indicated by the dots . . . ) – which should not be a
surprise since there is no simple finite expression for p, unless you
cheat with integral calculus. Here are a few of the high points.
    The first formula was one of the earliest expressions for p,
discovered by François Viète in 1593. It is related to polygons
with 2n sides:
                                      vﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
            rﬃﬃ sﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
                            rﬃﬃ u     u
                                                  sﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
                                                                   rﬃﬃ
        2      1    1 1 1 t1 1 1 1 1
          ¼      6    þ             6     þ                þ               6...
        p      2    2 2 2              2 2 2 2 2

The next was found by John Wallis in 1655:
        p 2 2 4 4 6 6 8 8
         ¼ 6 6 6 6 6 6 6 6...
        2 1 3 3 5 5 7 7 9
Around 1675, James Gregory and Gottfried Leibniz both
discovered
        p      1 1 1 1 1  1
          ¼ 1  þ  þ  þ  ...
        4      3 5 7 9 11 13
This converges too slowly to be of any help in calculating p; that
is, a good approximation requires oodles of terms. But closely
related series were used to find several hundred digits of p in the
eighteenth and nineteenth centuries. In the seventeenth cen-
tury, Lord Brouncker discovered an infinite ‘continued fraction’:
                         4
        p¼
                             12
             1þ
                                  32
                  2þ
                                       52
                       2þ
                                     72
                             2þ
                                   2 þ ...
and Euler discovered a pile of formulas like these:
                  1   1   1   1   1
         p2 ¼ 1 þ   þ þ þ þ þ ...
                 22 32 42 52 62
         p3       1   1   1   1    1
            ¼ 1  3 þ 3  3 þ 3  3 þ ...
         32      3   3   7   9   11
         p4       1   1   1   1   1
            ¼ 1 þ 4 þ 4 þ 4 þ 4 þ 4 þ ...
         90      2   3   4   5   6
210 // If p isn’t a Fraction, How Can You Calculate It?



(By the way, there seems to be no such formula for
            1  1  1  1  1
       1þ     þ þ þ þ þ ...
            23 33 43 53 63
which is very mysterious and not fully understood. In particular,
this sum is not any simple rational number times p3 . We do
know that the sum of the series is irrational.)
    For the other formulas, we’ll need the ‘sigma notation’ for
sums. The idea is that: we can write the series for p2 =6 in the
more compact form

       p2 X ?
               1
         ¼       2
       6   n¼1
               n

Let me unpack this. The fancy S symbol is Greek capital sigma, for
‘sum’, and it tells you to add together all the numbers to its right,
namely 1=n2 . The ‘n ¼ 1’ below the S says that we start adding
from n ¼ 1, and by convention n runs through the positive
integers. The symbol ? over the S which means ‘infinity’, tells us
to keep adding these numbers for ever. So this is the same series
for p2 =6 that we saw earlier, but written as an instruction ‘Add the
terms 1=n2 , for n ¼ 1; 2; 3, and so on, going on for ever.’
    Around 1985, Jonathan and Peter Borwein discovered the series
               pﬃﬃ ?
         1    2 2 X    ð4nÞ! 1;103 þ 26;390n
           ¼                 6
         p 9;801 n¼0 ðn!Þ4         ð4699Þ4n

which converges extremely rapidly. In 1997 David Bailey, Peter
Borwein and Simon Plouffe found an unprecedented formula,
          X?                                     n
                  4        2        1        1     1
      p¼                      –        –
          n¼0
               8n þ 1   8n þ 4   8n þ 5   8n þ 6   16

Why is this so special? It allows us to calculate a specific digit of p
without calculating the preceding digits. The only snag is that
these are not decimal digits: they are hexadecimal (base 16), from
which we can also work out a given digit in base 8 (octal), 4
(quaternary) or 2 (binary). In 1998 Fabrice Ballard used this
formula to show that the 100 billionth hexadecimal digit of p
                                                Infinite Wealth // 211



is 9. Within two years, the record had risen to 250 trillion
hexadecimal digits (one quadrillion binary digits).
    The current record for decimal digits of p is held by Yasumasa
Kanada and coworkers, who computed the first 1.2411 trillion


...........................................
digits in 2002.